<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rachel Wicks</title>

  <link rel="stylesheet" href="./assets/css/style.css">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600&display=swap" rel="stylesheet">
</head>

<body>

  <!--
    - #MAIN
  -->

  <main>

    <!--
      - #SIDEBAR
    -->

    <aside class="sidebar" data-sidebar>

      <div class="sidebar-info">

        <figure class="avatar-box">
          <img src="./assets/images/profile.png" alt="Rachel Wicks" width="80">
        </figure>

        <div class="info-content">
          <h1 class="name" title="Rachel Wicks">Rachel Wicks</h1>

          <p class="title">PhD Student</p>
        </div>

        <button class="info_more-btn" data-sidebar-btn>
          <span>Show Contacts</span>

          <ion-icon name="chevron-down"></ion-icon>
        </button>

      </div>

      <div class="sidebar-info_more">

        <div class="separator"></div>

        <ul class="contacts-list">

          <li class="contact-item">

            <div class="icon-box">
              <img src = "./assets/images/mail-outline.svg" width="60%" color="#6ee0ff"/>
            </div>

            <div class="contact-info">
              <p class="contact-title">Email</p>

              <a href="mailto:rewicks@jhu.edu" class="contact-link">rewicks@jhu.edu</a>
            </div>

          </li>


          <li class="contact-item">

            <div class="icon-box">
              <img src = "./assets/images/location-outline.svg" width="65%"/>

              <!-- <ion-icon name="location-outline"></ion-icon> -->
            </div>

            <div class="contact-info">
              <p class="contact-title">Location</p>

              <address>Johns Hopkins University</address>
            </div>

          </li>

        </ul>

        <div class="separator"></div>

        <ul class="social-list">

          <li class="social-item">
            <a href="https://github.com/rewicks" class="social-link">
              <img src = "./assets/images/github-mark-white.svg" class="social-link"/>
              <!-- <ion-icon name="logo-github"></ion-icon> -->
            </a>
          </li>

          <li class="social-item">
            <a href="https://huggingface.co/rewicks" class="social-link">
              <img src = "./assets/images/logo-huggingface.svg" class="social-link"/>
              <!-- <ion-icon name="logo-twitter"></ion-icon> -->
            </a>
          </li>

          <li class="social-item">
            <a href="https://scholar.google.com/citations?user=4YgNjmIAAAAJ&hl=en&oi=ao" class="social-link">
              <img src = "./assets/images/google-scholar-logo.svg" class="social-link"/>
            </a>
          </li>

        </ul>

      </div>

    </aside>



    <!--
      - #main-content
    -->

    <div class="main-content">

      <!--
        - #NAVBAR
      -->

      <nav class="navbar">

        <ul class="navbar-list">

          <li class="navbar-item">
            <button class="navbar-link  active" data-nav-link="about">About</button>
          </li>

          <li class="navbar-item">
            <button class="navbar-link" data-nav-link="publications">Publications</button>
          </li>

        </ul>

      </nav>

      <!--
        - #ABOUT
      -->

      <article class="about  active" data-page="about">

        <header>
          <h2 class="h2 article-title">About me</h2>
        </header>

        <section class="about-text">
          <p>
            I'm a final year PhD student at Johns Hopkins University. 
            For the past few years I've been working with <a href="https://waypost.net/">Matt Post</a> and <a href="https://www.cs.jhu.edu/~phi/">Philipp Koehn</a>.
            My research has focused on the nitty-gritty problems (read: <i>data</i> improvements) that oft get overlooked, targeting improvement in machine translation.
            More broadly, I'm interested in multilinguality in generative models, with experience in sequence to sequence modeling, corpus creation, and data augmentation.
          </p>

        </section>


        <!--
          - service
        -->

        <section class="service">

          <h3 class="h3 service-title">Projects</h3>

          <ul class="service-list">


            <li class="service-item">

              <div class="service-icon-box">
              </div>

              <div class="service-content-box">
                <a href="https://github.com/mjpost/abe">
                <h4 class="h4 service-item-title">Agreement Based Ensembling</h4>

                <p class="service-item-text">
                  A new inference technique to ensemble models with different vocabularies.
                </p>
                </a>
              </div>

            </li>


            <li class="service-item">

              <div class="service-icon-box">
              </div>

              <div class="service-content-box">
                <a href="https://huggingface.co/datasets/jhu-clsp/paradocs">
                <h4 class="h4 service-item-title">ParaDocs</h4>

                <p class="service-item-text">
                  A collection of parallel dataset with document-level annotations for context-aware machine translation.
                </p>
                </a>
              </div>

            </li>

            <li class="service-item">

              <div class="service-icon-box">
                <!-- <img src="./assets/images/icon-dev.svg" alt="Web development icon" width="40"> -->
              </div>

              <div class="service-content-box">
                <a href="https://github.com/rewicks/ctxpro">
                <h4 class="h4 service-item-title">CTXPRO</h4>

                <p class="service-item-text">
                  Automatically curated evaluation datasets to measure the ability to translate contextually-ambiguous discourse phenomena.
                </p>
                </a>
              </div>

            </li>

            <li class="service-item">

              <div class="service-icon-box">
                <!-- <img src="./assets/images/icon-app.svg" alt="mobile app icon" width="40"> -->
              </div>

              <div class="service-content-box">
                <h4 class="h4 service-item-title">LIDIRL</h4>

                <p class="service-item-text">
                  A series of robust language identification models that improve performance on the long tail of errors from noisy web text.
                </p>
              </div>

            </li>

            <li class="service-item">

              <div class="service-icon-box">
                <!-- <img src="./assets/images/icon-photo.svg" alt="camera icon" width="40"> -->
              </div>

              <div class="service-content-box">
                <a href="https://github.com/rewicks/ersatz">
                <h4 class="h4 service-item-title">ersatz</h4>

                <p class="service-item-text">
                  A training and inference framework for the task of sentence segmentation in many languages.
                </p>
                </a>
              </div>

            </li>

          </ul>

        </section>


        <section class="about-text">
          <p>
            This website is derived from a template you can find <a href="https://github.com/codewithsadee/vcard-personal-portfolio">here</a>.
          </p>

        </section>

      </article>


      <!--
        - #PUBLICATIONS
      -->

      <article class="publications" data-page="publications">

        <header>
          <h2 class="h2 article-title">Publications</h2>
        </header>

        <section class="projects">

          <ul class="filter-list">

            <li class="filter-item">
              <button class="active" data-filter-btn>All</button>
            </li>

            <li class="filter-item">
              <button data-filter-btn>Datasets</button>
            </li>

            <li class="filter-item">
              <button data-filter-btn>Methods</button>
            </li>

          </ul>

          <div class="filter-select-box">

            <button class="filter-select" data-select>

              <div class="select-value" data-selecct-value>Select category</div>

              <div class="select-icon">
                <ion-icon name="chevron-down"></ion-icon>
              </div>

            </button>

            <ul class="select-list">

              <li class="select-item">
                <button data-select-item>All</button>
              </li>

              <li class="select-item">
                <button data-select-item>Datasets</button>
              </li>

              <li class="select-item">
                <button data-select-item>Methods</button>
              </li>

            </ul>

          </div>

          <ul class="project-list">

            			<li class="project-item  active" data-filter-item data-category="methods">
				<a href="#" class="navbar-link" data-nav-link="abe">
					<figure class="project-img">
						<div class="project-item-icon-box">
							<ion-icon name="eye-outline"></ion-icon>
						</div>

						<img src="./assets/images/abe.png" alt="abe" loading="lazy">
					</figure>

					<h3 class="project-title">Token-level Ensembling of Models with Different Vocabularies</h3>

					<p class="project-category">Methods</p>

				</a>
			</li>

			<li class="project-item  active" data-filter-item data-category="datasets">
				<a href="#" class="navbar-link" data-nav-link="paradocs">
					<figure class="project-img">
						<div class="project-item-icon-box">
							<ion-icon name="eye-outline"></ion-icon>
						</div>

						<img src="./assets/images/paradocs.png" alt="Paradocs" loading="lazy">
					</figure>

					<h3 class="project-title">Recovering document annotations for sentence-level bitext</h3>

					<p class="project-category">Datasets</p>

				</a>
			</li>

			<li class="project-item  active" data-filter-item data-category="datasets">
				<a href="#" class="navbar-link" data-nav-link="ctxpro">
					<figure class="project-img">
						<div class="project-item-icon-box">
							<ion-icon name="eye-outline"></ion-icon>
						</div>

						<img src="./assets/images/ctxpro.png" alt="ctxpro" loading="lazy">
					</figure>

					<h3 class="project-title">Identifying Context-Dependent Translations for Evaluation Set Production</h3>

					<p class="project-category">Datasets</p>

				</a>
			</li>

			<li class="project-item  active" data-filter-item data-category="methods">
				<a href="#" class="navbar-link" data-nav-link="language-token-prefixing">
					<figure class="project-img">
						<div class="project-item-icon-box">
							<ion-icon name="eye-outline"></ion-icon>
						</div>

						<img src="./assets/images/language-tokens.png" alt="language token prefixes" loading="lazy">
					</figure>

					<h3 class="project-title">The Effects of Language Token Prefixing for Multilingual Machine Translation</h3>

					<p class="project-category">Methods</p>

				</a>
			</li>

			<li class="project-item  active" data-filter-item data-category="methods">
				<a href="#" class="navbar-link" data-nav-link="importance-of-sentence-segmentation">
					<figure class="project-img">
						<div class="project-item-icon-box">
							<ion-icon name="eye-outline"></ion-icon>
						</div>

						<img src="./assets/images/does-segmentation-matter.png" alt="Does Sentence Segmentation Matter?" loading="lazy">
					</figure>

					<h3 class="project-title">Does Sentence Segmentation Matter for Machine Translation?</h3>

					<p class="project-category">Methods</p>

				</a>
			</li>

			<li class="project-item  active" data-filter-item data-category="methods">
				<a href="#" class="navbar-link" data-nav-link="ersatz">
					<figure class="project-img">
						<div class="project-item-icon-box">
							<ion-icon name="eye-outline"></ion-icon>
						</div>

						<img src="./assets/images/ersatz.png" alt="ersatz" loading="lazy">
					</figure>

					<h3 class="project-title">A unified approach to sentence segmentation of punctuated text in many languages</h3>

					<p class="project-category">Methods</p>

				</a>
			</li>

			<li class="project-item  active" data-filter-item data-category="datasets">
				<a href="#" class="navbar-link" data-nav-link="jhubc">
					<figure class="project-img">
						<div class="project-item-icon-box">
							<ion-icon name="eye-outline"></ion-icon>
						</div>

						<img src="./assets/images/bible-corpus.png" alt="Johns Hopkins Bible Corpus" loading="lazy">
					</figure>

					<h3 class="project-title">The Johns Hopkins University Bible Corpus: 1600+ Tongues for Typological Exploration</h3>

					<p class="project-category">Datasets</p>

				</a>
			</li>


          </ul>

        </section>

      </article>


      			<article class="blog" data-page="abe">
				<header>
					<h2 class="h2 article-title">Token-level Ensembling of </p><p>Models with Different Vocabularies</p></h2>
				</header>
		<ul class="paper-list">
				<li class="paper-item">
					<a href="https://arxiv.org/abs/2502.21265v1">
						<h4 class="h4 paper-title">Paper</h4>
					</a>
				</li>
				<li class="paper-item">
					<a href="https://github.com/mjpost/abe">
						<h4 class="h4 paper-title">Code</h4>
					</a>
				</li>
		</ul>
		<section class="about-text">
			<p>
				Model ensembling is a technique to combine the predicted distributions of two or more models, often leading to improved robustness and performance. For ensembling in text generation, the next token’s probability distribution is derived from a weighted sum of the distributions of each individual model. This requires the underlying models to share the same subword vocabulary, limiting the applicability of ensembling, since many open-sourced models have distinct vocabularies. In research settings, experimentation or upgrades to vocabularies may introduce multiple vocabulary sizes. This paper proposes an inference-time only algorithm that allows for ensembling models with different vocabularies, without the need to learn additional parameters or alter the underlying models. Instead, the algorithm ensures that tokens generated by the ensembled models agree in their surface form. We apply this technique to combinations of traditional encoder-decoder models and decoder-only LLMs and evaluate on machine translation. In addition to expanding to model pairs that were previously incapable of token-level ensembling, our algorithm frequently improves translation performance over either model individually.			</p>
		</section>
			</article>

			<article class="blog" data-page="paradocs">
				<header>
					<h2 class="h2 article-title">Recovering document </p><p>annotations for sentence-level bitext</p></h2>
				</header>
		<ul class="paper-list">
				<li class="paper-item">
					<a href="https://aclanthology.org/2024.findings-acl.589/">
						<h4 class="h4 paper-title">Paper</h4>
					</a>
				</li>
				<li class="paper-item">
					<a href="https://huggingface.co/datasets/jhu-clsp/paradocs">
						<h4 class="h4 paper-title">Dataset</h4>
					</a>
				</li>
		</ul>
		<section class="about-text">
			<p>
				In machine translation, historical models were incapable of handling longer contexts, so the lack of document-level datasets was less noticeable. Now, despite the emergence of long-sequence methods, we remain within a sentence-level paradigm and without data to adequately approach context-aware machine translation. Most large-scale datasets have been processed through a pipeline that discards document-level metadata. In this work, we reconstruct document-level information for three (ParaCrawl, News Commentary, and Europarl) large datasets in German, French, Spanish, Italian, Polish, and Portuguese (paired with English). We then introduce a document-level filtering technique as an alternative to traditional bitext filtering. We present this filtering with analysis to show that this method prefers context-consistent translations rather than those that may have been sentence-level machine translated. Last we train models on these longer contexts and demonstrate improvement in document-level translation without degradation of sentence-level translation. We release our dataset, ParaDocs, and resulting models as a resource to the community.			</p>
		</section>
			</article>

			<article class="blog" data-page="ctxpro">
				<header>
					<h2 class="h2 article-title">Identifying Context-Dependent </p><p>Translations for Evaluation Set Production</p></h2>
				</header>
		<ul class="paper-list">
				<li class="paper-item">
					<a href="https://aclanthology.org/2023.wmt-1.42/">
						<h4 class="h4 paper-title">Paper</h4>
					</a>
				</li>
				<li class="paper-item">
					<a href="https://github.com/rewicks/ctxpro">
						<h4 class="h4 paper-title">Code</h4>
					</a>
				</li>
		</ul>
		<section class="about-text">
			<p>
				A major impediment to the transition to contextual machine translation is the absence of good evaluation metrics and test sets. Sentences that require context to be translated correctly are rare in test sets, reducing the utility of standard corpus-level metrics such as COMET or BLEU. On the other hand, datasets that annotate such sentences are also rare, small in scale, and available for only a few languages. To address this, we modernize, generalize, and extend previous annotation pipelines to produce MultiPro, a tool that identifies subsets of parallel documents containing sentences that require context to correctly translate five phenomena: gender, formality, and animacy for pronouns, verb phrase ellipsis, and ambiguous noun inflections. The input to the pipeline is a set of hand-crafted, per-language, linguistically-informed rules that select contextual sentence pairs using coreference, part-of-speech, and morphological features provided by state-of-the-art tools. We apply this pipeline to seven languages pairs (EN into and out-of DE, ES, FR, IT, PL, PT, and RU) and two datasets (OpenSubtitles and WMT test sets), and validate its performance using both overlap with previous work and its ability to discriminate a contextual MT system from a sentence-based one. We release the MultiPro pipeline and data as open source.			</p>
		</section>
			</article>

			<article class="blog" data-page="language-token-prefixing">
				<header>
					<h2 class="h2 article-title">The Effects of Language Token </p><p>Prefixing for Multilingual Machine Translation</p></h2>
				</header>
		<ul class="paper-list">
				<li class="paper-item">
					<a href="https://aclanthology.org/2022.aacl-short.19/">
						<h4 class="h4 paper-title">Paper</h4>
					</a>
				</li>
		</ul>
		<section class="about-text">
			<p>
				Machine translation traditionally refers to translating from a single source language into a single target language. In recent years, the field has moved towards large neural models either translating from or into many languages. The model must be correctly cued to translate into the correct target language. This is typically done by prefixing language tokens onto the source or target sequence. The location and content of the prefix can vary and many use different approaches without much justification towards one approach or another. As a guidance to future researchers and directions for future work, we present a series of experiments that show how the positioning and type of a target language prefix token effects translation performance. We show that source side prefixes improve performance. Further, we find that the best language information to denote via tokens depends on the supported language set.			</p>
		</section>
			</article>

			<article class="blog" data-page="importance-of-sentence-segmentation">
				<header>
					<h2 class="h2 article-title">Does Sentence Segmentation </p><p>Matter for Machine Translation?</p></h2>
				</header>
		<ul class="paper-list">
				<li class="paper-item">
					<a href="https://aclanthology.org/2022.wmt-1.78/">
						<h4 class="h4 paper-title">Paper</h4>
					</a>
				</li>
		</ul>
		<section class="about-text">
			<p>
				For the most part, NLP applications operate at the sentence level. Since sentences occur most naturally in documents, they must be extracted and segmented via the use of a segmenter, of which there are a handful of options. There has been some work evaluating the performance of segmenters on intrinsic metrics, that look at their ability to recover human-segmented sentence boundaries, but there has been no work looking at the effect of segmenters on downstream tasks. We ask the question, “does segmentation matter?” and attempt to answer it on the task of machine translation. We consider two settings: the application of segmenters to a black-box system whose training segmentation is mostly unknown, as well as the variation in performance when segmenters are applied to the training process, too. We find that the choice of segmenter largely does not matter, so long as its behavior is not one of extreme under- or over-segmentation. For such settings, we provide some qualitative analysis examining their harms, and point the way towards document-level processing.			</p>
		</section>
			</article>

			<article class="blog" data-page="ersatz">
				<header>
					<h2 class="h2 article-title">A unified approach to sentence </p><p>segmentation of punctuated text in many languages</p></h2>
				</header>
		<ul class="paper-list">
				<li class="paper-item">
					<a href="https://aclanthology.org/2021.acl-long.309/">
						<h4 class="h4 paper-title">Paper</h4>
					</a>
				</li>
				<li class="paper-item">
					<a href="https://github.com/rewicks/ersatz">
						<h4 class="h4 paper-title">Code</h4>
					</a>
				</li>
		</ul>
		<section class="about-text">
			<p>
				The sentence is a fundamental unit of text processing. Yet sentences in the wild are commonly encountered not in isolation, but unsegmented within larger paragraphs and documents. Therefore, the first step in many NLP pipelines is sentence segmentation. Despite its importance, this step is the subject of relatively little research. There are no standard test sets or even methods for evaluation, leaving researchers and engineers without a clear footing for evaluating and selecting models for the task. Existing tools have relatively small language coverage, and efforts to extend them to other languages are often ad hoc. We introduce a modern context-based modeling approach that provides a solution to the problem of segmenting punctuated text in many languages, and show how it can be trained on noisily-annotated data. We also establish a new 23-language multilingual evaluation set. Our approach exceeds high baselines set by existing methods on prior English corpora (WSJ and Brown corpora), and also performs well on average on our new evaluation set. We release our tool, ersatz, as open source.			</p>
		</section>
			</article>

			<article class="blog" data-page="jhubc">
				<header>
					<h2 class="h2 article-title">The Johns Hopkins University </p><p>Bible Corpus: 1600+ Tongues for Typological Exploration</p></h2>
				</header>
		<ul class="paper-list">
				<li class="paper-item">
					<a href="https://aclanthology.org/2020.lrec-1.352/">
						<h4 class="h4 paper-title">Paper</h4>
					</a>
				</li>
		</ul>
		<section class="about-text">
			<p>
				We present findings from the creation of a massively parallel corpus in over 1600 languages, the Johns Hopkins University Bible Corpus (JHUBC). The corpus consists of over 4000 unique translations of the Christian Bible and counting. Our data is derived from scraping several online resources and merging them with existing corpora, combining them under a common scheme that is verse-parallel across all translations. We detail our effort to scrape, clean, align, and utilize this ripe multilingual dataset. The corpus captures the great typological variety of the world’s languages. We catalog this by showing highly similar proportions of representation of Ethnologue’s typological features in our corpus. We also give an example application: projecting pronoun features like clusivity across alignments to richly annotate languages which do not mark the distinction.			</p>
		</section>
			</article>



      <!--
        - #BLOG
      -->



    </div>

  </main>






  <!--
    - custom js link
  -->
  <script src="./assets/js/script.js"></script>

  <!--
    - ionicon link
  -->
  <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>

</body>

</html>
